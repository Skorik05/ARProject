{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import models\n",
    "\n",
    "def predict(img):\n",
    "    i = 0\n",
    "    tf.reset_default_graph()\n",
    "    model_data_path = \"NYU_FCRN.ckpt\"\n",
    "    \n",
    "    height = 228\n",
    "    width = 304\n",
    "    channels = 3\n",
    "    batch_size = 1\n",
    "    \n",
    "    input_node = tf.placeholder(tf.float32, shape=(None, height, width, channels))\n",
    "\n",
    "    net = models.ResNet50UpProj({'data': input_node}, batch_size, 1, False)\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()     \n",
    "        saver.restore(sess, model_data_path)\n",
    "        img = img.resize([width,height], Image.ANTIALIAS)\n",
    "        img = np.array(img).astype('float32')\n",
    "        img = np.expand_dims(np.asarray(img), axis = 0)\n",
    "        pred = sess.run(net.get_output(), feed_dict={input_node: img})\n",
    "        \n",
    "        return pred[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import natsort\n",
    "from os import listdir\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "directory1 = '/picsDB/'\n",
    "directory2 = '/depthDB/'\n",
    "dirs = natsort.natsorted(os.listdir( directory1 ))\n",
    "data = pd.read_csv(\"DB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "q = random.sample(range(0, 11500), 11500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('ARdataset.h5', 'a') as hdf:\n",
    "    x_train = hdf.create_dataset('x_train', (10000,224,224,4),\n",
    "                            dtype='float32', chunks=(10**3,224,224,4))\n",
    "    y_train = hdf.create_dataset('y_train', (10000,12),\n",
    "                            dtype='float32', chunks=(10**3,12))\n",
    "    x_test = hdf.create_dataset('x_test', (1500,224,224,4),\n",
    "                            dtype='float32', chunks=(10**3,224,224,4))\n",
    "    y_test = hdf.create_dataset('y_test', (1500,12),\n",
    "                            dtype='float32', chunks=(10**3,12))\n",
    "    with h5py.File('DBrgbd.h5', 'a') as hd:\n",
    "        for i in range(0,10000):\n",
    "            x_train[i]=hd['x_train'][q[i]]\n",
    "            y_train[i]=(hd['y_train'][q[i]])\n",
    "            if(i%1000==0):\n",
    "                print(i)\n",
    "        for i in range(10000,11500):\n",
    "            x_train[11499-i]=hd['x_train'][q[i]]\n",
    "            y_train[11499-i]=hd['y_train'][q[i]]\n",
    "            if(i%1000==0):\n",
    "                print(y_train[11499-i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06        0.78        0.68        1.         -0.33333334  0.46\n",
      "  0.34        1.          0.18        0.6666667  -0.06666667  0.        ]\n"
     ]
    }
   ],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 1)       101       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 1)       10        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 1)         10        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 1)         10        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 1)         10        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               25000     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                6012      \n",
      "=================================================================\n",
      "Total params: 31,153\n",
      "Trainable params: 31,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " 2600/31088 [=>............................] - ETA: 14:07 - loss: 0.2101 - acc: 0.4712"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with h5py.File('DBrgbd.h5', 'r') as hdf:\n",
    "    X, Y =  hdf['x_train'], hdf['y_train']\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(1, (5, 5), input_shape=(224, 224, 4),padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(1, (3, 3), input_shape=(112, 112, 4),padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(1, (3, 3), input_shape=(56, 56, 4),padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(1, (3, 3), input_shape=(28, 28, 4),padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(1, (3, 3), input_shape=(14, 14, 4),padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500,activation='tanh'))\n",
    "    model.add(Dense(12,activation='tanh'))\n",
    "    sgd = optimizers.SGD(lr=0.01)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    model.fit(X,Y,shuffle=\"batch\",batch_size=100,epochs=10,verbose=1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from NYU_FCRN.ckpt\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "img = Image.open('1.jpg')\n",
    "depthMap = predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = img.resize([160, 128], Image.ANTIALIAS)\n",
    "data = cv2.resize(np.append(img,depthMap,axis=2),(224,224))\n",
    "data=np.expand_dims(data,axis=0)\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "with open('model_arch.json','r') as f:\n",
    "    model = model_from_json(f.read())\n",
    "model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.48599586, 11.96957588,  7.29419008,  0.60981941, -0.39890623,\n",
       "         0.67384344, -7.46860966,  0.83537441,  1.03508379, 10.70313692,\n",
       "        -4.6847257 ,  0.8592602 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data)*(15,15,15,1,15,15,15,1,15,15,15,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
